{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 3: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll see examples of how to use the scikit-learn logistic regression class, as well as the statsmodels GLM function, which is much more similar to R's glm function for doing logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can read about the scikit-learn logistic regression function here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":0: FutureWarning: IPython widgets are experimental and may change in the future.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# sklearn.metrics has a bunch of really handy functions for measuring accuracy in classification\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_curve, roc_auc_score\n",
    "from sklearn import datasets\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the famous iris dataset, which has measured features of different species of iris:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get some documentation on the iris data set we just loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "?datasets.load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the ```iris``` object we created using ```load_iris()``` is not just a data frame.  It is actually an object that stores\n",
    "  * ```data```: the features, or $X$, data\n",
    "  * ```target```: the labels, or $Y$, data, stored as numbers\n",
    "  * ```target_names```: the meaning of the numerical labels stored in ```target```\n",
    "  * ```feature_names```: the column names for the features\n",
    "  * ```DESCR```: a description of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We see that we have four predictors\n",
    "iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The output is coded as either 0,1, or 2\n",
    "iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Each output code is a type of iris\n",
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The predictors are different measurements of the plant (sepal and pedal)\n",
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris Plants Database\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML iris datasets.\n",
      "http://archive.ics.uci.edu/ml/datasets/Iris\n",
      "\n",
      "The famous Iris database, first used by Sir R.A Fisher\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      "References\n",
      "----------\n",
      "   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The description tells us more information about the data set\n",
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a dataset which is only the first two predictors to keep things simple.  Notice that in this case, we have a response with more than two classes.  This is referrred to as the *multiclass* case.  scikit-learn lets you do this without any extra work.  On the backend, it will actually fit one binary logistic regression per class, trying to predict if each observation belongs to that class or not.  In order to make a prediction, it first makes predictions using each of the binary logistic regressions, then assigns the observation to the class with the highest score. This is call the 'one-vs-all' or 'one-vs-rest' approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = iris.data[:, :2]\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's construct and fit our scikit-learn classifier, which should follow the by-now-familiar workflow of construct, fit, predict that we saw with k-nearest neighbors and linear regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Construct a logistic regression.  The parameter 'C' tells Python how much regularization to do when fitting the model\n",
    "# We'll get to regularization next week, but basically when C is large, we're doing standard logistic regression.\n",
    "logit = LogisticRegression(C=1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the second argument in the output above, ```class_weight```.  This argument lets you penalize misclassification differently based on the class.  For instance, if false negatives are very important (cases when $y_{i}=1$ but $\\hat{y}_{i}=0$), then you can more heavily penalize them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's make predictions on our dataset.  In classification, there are usually two ways to predict -predict the probability of an observation being in each class, or actually assign an observation to a single class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 2, 2, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1,\n",
       "       1, 2, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2,\n",
       "       1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1,\n",
       "       2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n",
       "       1, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, using the .predict() call we get back predicted class assignments\n",
    "training_preds = logit.predict(X)\n",
    "training_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.05823905e-01,   6.81672013e-02,   2.60088939e-02],\n",
       "       [  7.64631786e-01,   2.16376590e-01,   1.89916235e-02],\n",
       "       [  8.46908157e-01,   1.42190177e-01,   1.09016662e-02],\n",
       "       [  8.15654921e-01,   1.75608861e-01,   8.73621791e-03],\n",
       "       [  9.29624966e-01,   5.11184180e-02,   1.92566160e-02],\n",
       "       [  9.35726243e-01,   2.14566456e-02,   4.28171113e-02],\n",
       "       [  9.06375214e-01,   8.58410376e-02,   7.78374790e-03],\n",
       "       [  8.90004223e-01,   8.86750246e-02,   2.13207520e-02],\n",
       "       [  7.44055159e-01,   2.50433077e-01,   5.51176369e-03],\n",
       "       [  8.02826805e-01,   1.78629207e-01,   1.85439881e-02],\n",
       "       [  9.12881392e-01,   3.90028926e-02,   4.81157159e-02],\n",
       "       [  8.99673219e-01,   8.73972775e-02,   1.29295031e-02],\n",
       "       [  7.69594524e-01,   2.15588498e-01,   1.48169774e-02],\n",
       "       [  7.86468274e-01,   2.09354239e-01,   4.17748690e-03],\n",
       "       [  8.85195466e-01,   1.56532847e-02,   9.91512491e-02],\n",
       "       [  9.32634691e-01,   4.55482910e-03,   6.28104799e-02],\n",
       "       [  9.35726243e-01,   2.14566456e-02,   4.28171113e-02],\n",
       "       [  9.05823905e-01,   6.81672013e-02,   2.60088939e-02],\n",
       "       [  8.81775462e-01,   2.88045719e-02,   8.94199658e-02],\n",
       "       [  9.49486589e-01,   2.85752663e-02,   2.19381451e-02],\n",
       "       [  8.54552240e-01,   8.97543407e-02,   5.56934189e-02],\n",
       "       [  9.38192573e-01,   3.84987122e-02,   2.33087152e-02],\n",
       "       [  9.43795525e-01,   4.92109497e-02,   6.99352520e-03],\n",
       "       [  8.56761685e-01,   1.14824908e-01,   2.84134063e-02],\n",
       "       [  8.99673219e-01,   8.73972775e-02,   1.29295031e-02],\n",
       "       [  7.58705901e-01,   2.17008582e-01,   2.42855166e-02],\n",
       "       [  8.90004223e-01,   8.86750246e-02,   2.13207520e-02],\n",
       "       [  8.98331697e-01,   6.84864517e-02,   3.31818511e-02],\n",
       "       [  8.75765839e-01,   8.94880130e-02,   3.47461479e-02],\n",
       "       [  8.46908157e-01,   1.42190177e-01,   1.09016662e-02],\n",
       "       [  8.07768520e-01,   1.77773939e-01,   1.44575408e-02],\n",
       "       [  8.54552240e-01,   8.97543407e-02,   5.56934189e-02],\n",
       "       [  9.65419251e-01,   1.14464175e-02,   2.31343318e-02],\n",
       "       [  9.46602696e-01,   8.51320169e-03,   4.48841019e-02],\n",
       "       [  8.02826805e-01,   1.78629207e-01,   1.85439881e-02],\n",
       "       [  8.32257392e-01,   1.44697291e-01,   2.30453165e-02],\n",
       "       [  8.64274530e-01,   6.87165294e-02,   6.70089405e-02],\n",
       "       [  8.02826805e-01,   1.78629207e-01,   1.85439881e-02],\n",
       "       [  7.83804870e-01,   2.10802074e-01,   5.39305589e-03],\n",
       "       [  8.83578139e-01,   8.91540136e-02,   2.72678469e-02],\n",
       "       [  9.11942320e-01,   6.77418370e-02,   2.03158428e-02],\n",
       "       [  5.48424664e-01,   4.43106994e-01,   8.46834185e-03],\n",
       "       [  8.56145337e-01,   1.38772958e-01,   5.08170440e-03],\n",
       "       [  9.11942320e-01,   6.77418370e-02,   2.03158428e-02],\n",
       "       [  9.49486589e-01,   2.85752663e-02,   2.19381451e-02],\n",
       "       [  7.69594524e-01,   2.15588498e-01,   1.48169774e-02],\n",
       "       [  9.49486589e-01,   2.85752663e-02,   2.19381451e-02],\n",
       "       [  8.50418487e-01,   1.41119103e-01,   8.46240963e-03],\n",
       "       [  9.23125527e-01,   3.89138100e-02,   3.79606633e-02],\n",
       "       [  8.63440513e-01,   1.14319744e-01,   2.22397430e-02],\n",
       "       [  8.72446141e-22,   2.06253776e-01,   7.93746224e-01],\n",
       "       [  1.20934054e-13,   2.81057482e-01,   7.18942518e-01],\n",
       "       [  1.15300958e-21,   2.52869938e-01,   7.47130062e-01],\n",
       "       [  1.42866352e-12,   8.25492553e-01,   1.74507447e-01],\n",
       "       [  5.89709250e-20,   4.24870776e-01,   5.75129224e-01],\n",
       "       [  4.50765015e-09,   7.04165933e-01,   2.95834062e-01],\n",
       "       [  4.96959832e-11,   2.61017276e-01,   7.38982724e-01],\n",
       "       [  2.69053427e-03,   9.47686199e-01,   4.96232672e-02],\n",
       "       [  4.47639838e-20,   3.69771096e-01,   6.30228904e-01],\n",
       "       [  1.41418505e-03,   8.87461330e-01,   1.11124485e-01],\n",
       "       [  1.63611250e-09,   9.33261505e-01,   6.67384936e-02],\n",
       "       [  2.78261580e-09,   5.49481304e-01,   4.50518694e-01],\n",
       "       [  1.52052633e-20,   6.57200887e-01,   3.42799113e-01],\n",
       "       [  2.83933702e-13,   5.04830477e-01,   4.95169523e-01],\n",
       "       [  1.88638798e-06,   7.21065096e-01,   2.78933018e-01],\n",
       "       [  5.78618140e-19,   2.72309750e-01,   7.27690250e-01],\n",
       "       [  3.51070102e-05,   6.90184309e-01,   3.09780583e-01],\n",
       "       [  1.10229617e-11,   6.84441718e-01,   3.15558282e-01],\n",
       "       [  3.02272560e-23,   5.98870805e-01,   4.01129195e-01],\n",
       "       [  1.84558320e-11,   7.86340742e-01,   2.13659258e-01],\n",
       "       [  9.27201624e-07,   4.57288512e-01,   5.42710561e-01],\n",
       "       [  1.60661034e-14,   5.39203926e-01,   4.60796074e-01],\n",
       "       [  6.11904144e-21,   5.46353327e-01,   4.53646673e-01],\n",
       "       [  1.60661034e-14,   5.39203926e-01,   4.60796074e-01],\n",
       "       [  2.30781136e-17,   4.10616104e-01,   5.89383896e-01],\n",
       "       [  7.66684770e-19,   3.29091849e-01,   6.70908151e-01],\n",
       "       [  5.29672579e-24,   3.80394515e-01,   6.19605485e-01],\n",
       "       [  3.39743786e-20,   3.14530076e-01,   6.85469924e-01],\n",
       "       [  6.60137150e-12,   5.44610769e-01,   4.55389231e-01],\n",
       "       [  1.42309095e-11,   7.40170024e-01,   2.59829976e-01],\n",
       "       [  2.40955232e-11,   8.24053957e-01,   1.75946043e-01],\n",
       "       [  2.40955232e-11,   8.24053957e-01,   1.75946043e-01],\n",
       "       [  1.10229617e-11,   6.84441718e-01,   3.15558282e-01],\n",
       "       [  2.10446283e-14,   6.04311053e-01,   3.95688947e-01],\n",
       "       [  1.79354147e-02,   7.62565871e-01,   2.19498715e-01],\n",
       "       [  1.24863700e-05,   3.12007700e-01,   6.87979814e-01],\n",
       "       [  5.78618140e-19,   2.72309750e-01,   7.27690250e-01],\n",
       "       [  2.21823877e-23,   5.68910927e-01,   4.31089073e-01],\n",
       "       [  3.51070102e-05,   6.90184309e-01,   3.09780583e-01],\n",
       "       [  4.12997927e-10,   8.19852479e-01,   1.80147520e-01],\n",
       "       [  7.20885062e-09,   8.12294073e-01,   1.87705920e-01],\n",
       "       [  5.05527210e-12,   4.64632073e-01,   5.35367927e-01],\n",
       "       [  6.27749695e-13,   7.01424111e-01,   2.98575889e-01],\n",
       "       [  7.33159320e-06,   9.37593390e-01,   6.23992788e-02],\n",
       "       [  5.69236336e-09,   7.64125371e-01,   2.35874623e-01],\n",
       "       [  1.51678040e-06,   6.43404602e-01,   3.56593881e-01],\n",
       "       [  8.21751509e-08,   6.77081726e-01,   3.22918191e-01],\n",
       "       [  1.22391545e-14,   4.68960435e-01,   5.31039565e-01],\n",
       "       [  9.83269276e-05,   9.19490903e-01,   8.04107700e-02],\n",
       "       [  4.50765015e-09,   7.04165933e-01,   2.95834062e-01],\n",
       "       [  4.96959832e-11,   2.61017276e-01,   7.38982724e-01],\n",
       "       [  1.10229617e-11,   6.84441718e-01,   3.15558282e-01],\n",
       "       [  1.41207875e-25,   2.82760602e-01,   7.17239398e-01],\n",
       "       [  5.29862838e-16,   4.37505938e-01,   5.62494062e-01],\n",
       "       [  1.74519274e-17,   3.47307593e-01,   6.52692407e-01],\n",
       "       [  2.94210680e-32,   2.74531043e-01,   7.25468957e-01],\n",
       "       [  4.33321990e-02,   9.07896923e-01,   4.87708776e-02],\n",
       "       [  1.77959112e-29,   3.16490053e-01,   6.83509947e-01],\n",
       "       [  2.49807853e-26,   4.72571286e-01,   5.27428714e-01],\n",
       "       [  1.31170531e-19,   7.81040222e-02,   9.21895978e-01],\n",
       "       [  5.18426688e-15,   2.60338725e-01,   7.39661275e-01],\n",
       "       [  7.78730076e-20,   4.77984800e-01,   5.22015200e-01],\n",
       "       [  1.51803800e-21,   3.03099024e-01,   6.96900976e-01],\n",
       "       [  8.20655756e-13,   7.50427933e-01,   2.49572067e-01],\n",
       "       [  1.96667857e-10,   6.61484294e-01,   3.38515706e-01],\n",
       "       [  1.20934054e-13,   2.81057482e-01,   7.18942518e-01],\n",
       "       [  1.74519274e-17,   3.47307593e-01,   6.52692407e-01],\n",
       "       [  6.86592081e-24,   4.29391007e-02,   9.57060899e-01],\n",
       "       [  1.80977068e-38,   4.09142590e-01,   5.90857410e-01],\n",
       "       [  1.52052633e-20,   6.57200887e-01,   3.42799113e-01],\n",
       "       [  1.93902883e-20,   2.12184620e-01,   7.87815380e-01],\n",
       "       [  1.02761402e-07,   7.45542262e-01,   2.54457635e-01],\n",
       "       [  4.93494528e-36,   3.50087883e-01,   6.49912117e-01],\n",
       "       [  1.76431563e-18,   5.03684018e-01,   4.96315982e-01],\n",
       "       [  1.66173494e-16,   1.90749933e-01,   8.09250067e-01],\n",
       "       [  1.80239853e-24,   1.98855452e-01,   8.01144548e-01],\n",
       "       [  6.97994415e-16,   5.04278647e-01,   4.95721353e-01],\n",
       "       [  5.05527210e-12,   4.64632073e-01,   5.35367927e-01],\n",
       "       [  1.33551699e-18,   4.47050183e-01,   5.52949817e-01],\n",
       "       [  6.46809022e-27,   2.79286483e-01,   7.20713517e-01],\n",
       "       [  4.93239346e-32,   3.51497540e-01,   6.48502460e-01],\n",
       "       [  1.47501942e-26,   4.32647066e-02,   9.56735293e-01],\n",
       "       [  1.33551699e-18,   4.47050183e-01,   5.52949817e-01],\n",
       "       [  3.04465797e-17,   4.73491230e-01,   5.26508770e-01],\n",
       "       [  5.31861649e-17,   5.89057807e-01,   4.10942193e-01],\n",
       "       [  1.36586407e-33,   2.74761475e-01,   7.25238525e-01],\n",
       "       [  8.62336949e-10,   2.18205082e-01,   7.81794917e-01],\n",
       "       [  6.96657826e-15,   3.25817855e-01,   6.74182145e-01],\n",
       "       [  1.18608184e-10,   5.05307868e-01,   4.94692132e-01],\n",
       "       [  1.15300958e-21,   2.52869938e-01,   7.47130062e-01],\n",
       "       [  5.78618140e-19,   2.72309750e-01,   7.27690250e-01],\n",
       "       [  1.15300958e-21,   2.52869938e-01,   7.47130062e-01],\n",
       "       [  1.10229617e-11,   6.84441718e-01,   3.15558282e-01],\n",
       "       [  4.34524375e-19,   2.20087641e-01,   7.79912359e-01],\n",
       "       [  1.66173494e-16,   1.90749933e-01,   8.09250067e-01],\n",
       "       [  3.39743786e-20,   3.14530076e-01,   6.85469924e-01],\n",
       "       [  6.11904144e-21,   5.46353327e-01,   4.53646673e-01],\n",
       "       [  1.74519274e-17,   3.47307593e-01,   6.52692407e-01],\n",
       "       [  2.08841089e-08,   2.44263730e-01,   7.55736249e-01],\n",
       "       [  2.78261580e-09,   5.49481304e-01,   4.50518694e-01]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Second, using the predict_proba() call we get back the probability that each observation is a 0, 1, or 2\n",
    "training_probs = logit.predict_proba(X)\n",
    "training_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 50,  51,  52,  54,  56,  58,  65,  70,  74,  75,  76,  77,  85,\n",
       "         86,  91,  97, 101, 106, 113, 114, 119, 121, 123, 126, 134, 138,\n",
       "        142, 146, 149]),)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we want to see where we made mistakes, we can do that by finding obserations where\n",
    "# our predictions don't match the true labels\n",
    "np.where(training_preds!=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[  8.72446141e-22   2.06253776e-01   7.93746224e-01]\n"
     ]
    }
   ],
   "source": [
    "# Here we look at one of the mistakes (the first one in the list above) in more detail.\n",
    "num = 50\n",
    "print y[num]\n",
    "print training_probs[num]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Classifier Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the very top, we imported several functions from sklearn.metrics ([http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)).\n",
    "\n",
    "First, we'll build a confusion matrix.  Note that the confusion matrix setup for the case with two cases readily extends to the case with more than two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "?confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50,  0,  0],\n",
       "       [ 0, 34, 16],\n",
       "       [ 0, 13, 37]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gives us what we want, but it's hard to read\n",
    "confusion_matrix(y, training_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the crosstab function in pandas, which has the advantage that it's clear which are rows and which are columns (http://pandas.pydata.org/pandas-docs/version/0.15.1/generated/pandas.crosstab.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2\n",
       "True                 \n",
       "0          50   0   0\n",
       "1           0  34  16\n",
       "2           0  13  37"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(index=y, columns=training_preds, rownames=['True'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the confusion matrix, it looks like our model does a good job of predicting the label $0$ ('setosa'), but gets somewhat confused when trying to distinguish labels $1$ and $2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we calculate the accuracy score for our predictions.  This is just the 1-misclassification rate, or the proportion of observations that were *correctly* classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.806666666667\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print accuracy_score(y, training_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `classification_report` function will easily give us some other metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       1.00      1.00      1.00        50\n",
      "    class 1       0.72      0.68      0.70        50\n",
      "    class 2       0.70      0.74      0.72        50\n",
      "\n",
      "avg / total       0.81      0.81      0.81       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y, training_preds, labels=[0,1,2], target_names=['class 0', 'class 1', 'class 2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In lecture, we described precision and recall in terms of true positives, false positives, etc., in the binary classification case.  Even though we're now dealing with more than two classes, we can still these metrics for each class.  For example, recall (# True Positive / # Actual Positives) for class 0 is just the number of observations assigned to class 0 that were actually in class 0 divided by the number of actual observations in class 0.  The same idea applies when calculating precision for each class.  The *f1-score*, which applies even in the binary class setting, is just a combination of precision and recall ($2\\cdot \\text{harmonic mean}$) with the best possible value of 1 and worst possible value 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make an ROC curve, let's simplify things and train a binary version rather than a multi-class version of the classifier.  We'll create a new set of binary responses equal to 1 when the origial class is 2, and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02871297,  0.02483682,  0.01287231,  0.01071068,  0.02071439,\n",
       "        0.04575816,  0.00858778,  0.02395579,  0.00740774,  0.02309832,\n",
       "        0.05270749,  0.01437133,  0.01925294,  0.0053117 ,  0.11200697,\n",
       "        0.06734736,  0.04575816,  0.02871297,  0.10137136,  0.02310527,\n",
       "        0.06502151,  0.02484428,  0.00741   ,  0.0331636 ,  0.01437133,\n",
       "        0.03198735,  0.02395579,  0.03693718,  0.03967496,  0.01287231,\n",
       "        0.01789812,  0.06502151,  0.02396299,  0.04741599,  0.02309832,\n",
       "        0.02769006,  0.07728785,  0.02309832,  0.00688061,  0.0308607 ,\n",
       "        0.02227755,  0.01490073,  0.00593556,  0.02227755,  0.02310527,\n",
       "        0.01925294,  0.02310527,  0.00995088,  0.04112189,  0.02575712,\n",
       "        0.83873714,  0.52164216,  0.81196618,  0.16972174,  0.65574497,\n",
       "        0.19176287,  0.43829153,  0.03826557,  0.69644247,  0.06500279,\n",
       "        0.06498407,  0.25606043,  0.44734927,  0.3842727 ,  0.14513026,\n",
       "        0.71952174,  0.1361472 ,  0.24901464,  0.57672897,  0.18604385,\n",
       "        0.22877468,  0.40200848,  0.58581417,  0.40200848,  0.57680416,\n",
       "        0.68049895,  0.80620055,  0.73427835,  0.3247944 ,  0.21586985,\n",
       "        0.15950055,  0.15950055,  0.24901464,  0.35821311,  0.08561337,\n",
       "        0.24907224,  0.71952174,  0.62137407,  0.1361472 ,  0.14978386,\n",
       "        0.14056012,  0.36683938,  0.26317598,  0.05267674,  0.16456859,\n",
       "        0.16976515,  0.18050286,  0.44742542,  0.05853624,  0.19176287,\n",
       "        0.43829153,  0.24901464,  0.8867466 ,  0.51232115,  0.62144653,\n",
       "        0.9664242 ,  0.03562144,  0.93419726,  0.80030161,  0.86671432,\n",
       "        0.5858889 ,  0.61262609,  0.78190662,  0.22872034,  0.23537189,\n",
       "        0.52164216,  0.62144653,  0.95370779,  0.98049838,  0.44734927,\n",
       "        0.80035083,  0.15459995,  0.97744239,  0.54933675,  0.6885596 ,\n",
       "        0.8974869 ,  0.4658706 ,  0.36683938,  0.59484136,  0.91038171,\n",
       "        0.95201752,  0.97197219,  0.59484136,  0.53087141,  0.4382157 ,\n",
       "        0.97392025,  0.4200795 ,  0.5401561 ,  0.30870657,  0.81196618,\n",
       "        0.71952174,  0.81196618,  0.24901464,  0.75549093,  0.6885596 ,\n",
       "        0.73427835,  0.58581417,  0.62144653,  0.35828393,  0.25606043])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_bin = (y==2).astype(\"int\")\n",
    "\n",
    "logit_binary = LogisticRegression(C=1e5)\n",
    "logit_binary.fit(X, y_bin)\n",
    "\n",
    "bin_preds = logit_binary.predict_proba(X)[:, 1] # In binary response case, probability of 0 is 1 - probability of 1.\n",
    "bin_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `roc_curve` function returns three arrays.  One for the false positive rate, one for the true positive rate, and one for the probability thresholds that correspond to each point.  We don't plot the thresholds directly in an ROC curve, but it's by tracing out the true positive and false positive rates as we range over the threhold that we obtain the curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_bin, bin_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.98049838,  0.86671432,  0.83873714,  0.81196618,  0.80620055,\n",
       "        0.75549093,  0.73427835,  0.71952174,  0.69644247,  0.6885596 ,\n",
       "        0.65574497,  0.62144653,  0.62137407,  0.61262609,  0.59484136,\n",
       "        0.5858889 ,  0.58581417,  0.57672897,  0.53087141,  0.52164216,\n",
       "        0.4658706 ,  0.44742542,  0.43829153,  0.4200795 ,  0.40200848,\n",
       "        0.3842727 ,  0.36683938,  0.35828393,  0.3247944 ,  0.30870657,\n",
       "        0.26317598,  0.25606043,  0.24907224,  0.24901464,  0.23537189,\n",
       "        0.22877468,  0.22872034,  0.21586985,  0.19176287,  0.16456859,\n",
       "        0.15950055,  0.15459995,  0.14056012,  0.1361472 ,  0.06734736,\n",
       "        0.06502151,  0.04741599,  0.04575816,  0.03693718,  0.03562144,\n",
       "        0.0308607 ,  0.02871297,  0.02396299,  0.02395579,  0.02309832,\n",
       "        0.02227755,  0.02071439,  0.01925294,  0.01490073,  0.01287231,\n",
       "        0.0053117 ])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll plot the ROC curve, but also the baseline 'random guessing' diagonal for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAegAAAFVCAYAAAAkBHynAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1174153d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr_rand = tpr_rand = np.linspace(0, 1, 10) # Construct the random baseline\n",
    "\n",
    "plt.plot(fpr, tpr) # Add the ROC curve to our plot\n",
    "plt.plot(fpr_rand, tpr_rand, linestyle='--') # Add the random baseline to our plot\n",
    "plt.show() # Show the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can easily calculate the AUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88730000000000009"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_bin, bin_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the **lift curve**.  The lift curve tries to answer the following question: if you rank ordered all of your observations in decreasing order of their probability of being a positive, what percent of the overall number of observations would you need to target in order to have reached a specified percent of the *actual* positives in the population?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A natural case is in marketing, where you often want to launch a direct marketing campaign to acquire new customers.  You have a limited budget, so you can't reach everyone.  Therefore, you cut your target by taking the top $5\\%$, $10\\%$, etc., of individuals based on their probability of accepting your offer. The idea is that, if the model is good, then that target should contain a sizable fraction of the consumers you actually have a chance of converting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unforunately, we have to make a lift curve by hand -it's not built into sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First, order the scores from highest to lowest.\n",
    "order = np.argsort(bin_preds)\n",
    "# this notation means go from beginning to end by -1, which is reverse order\n",
    "decreasing_order = order[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.98049838,  0.97744239,  0.97392025,  0.97197219,  0.9664242 ,\n",
       "        0.95370779,  0.95201752,  0.93419726,  0.91038171,  0.8974869 ,\n",
       "        0.8867466 ,  0.86671432,  0.83873714,  0.81196618,  0.81196618,\n",
       "        0.81196618,  0.80620055,  0.80035083,  0.80030161,  0.78190662,\n",
       "        0.75549093,  0.73427835,  0.73427835,  0.71952174,  0.71952174,\n",
       "        0.71952174,  0.69644247,  0.6885596 ,  0.6885596 ,  0.68049895,\n",
       "        0.65574497,  0.62144653,  0.62144653,  0.62144653,  0.62137407,\n",
       "        0.61262609,  0.59484136,  0.59484136,  0.5858889 ,  0.58581417,\n",
       "        0.58581417,  0.57680416,  0.57672897,  0.54933675,  0.5401561 ,\n",
       "        0.53087141,  0.52164216,  0.52164216,  0.51232115,  0.4658706 ,\n",
       "        0.44742542,  0.44734927,  0.44734927,  0.43829153,  0.43829153,\n",
       "        0.4382157 ,  0.4200795 ,  0.40200848,  0.40200848,  0.3842727 ,\n",
       "        0.36683938,  0.36683938,  0.35828393,  0.35821311,  0.3247944 ,\n",
       "        0.30870657,  0.26317598,  0.25606043,  0.25606043,  0.24907224,\n",
       "        0.24901464,  0.24901464,  0.24901464,  0.24901464,  0.23537189,\n",
       "        0.22877468,  0.22872034,  0.21586985,  0.19176287,  0.19176287,\n",
       "        0.18604385,  0.18050286,  0.16976515,  0.16972174,  0.16456859,\n",
       "        0.15950055,  0.15950055,  0.15459995,  0.14978386,  0.14513026,\n",
       "        0.14056012,  0.1361472 ,  0.1361472 ,  0.11200697,  0.10137136,\n",
       "        0.08561337,  0.07728785,  0.06734736,  0.06502151,  0.06502151,\n",
       "        0.06500279,  0.06498407,  0.05853624,  0.05270749,  0.05267674,\n",
       "        0.04741599,  0.04575816,  0.04575816,  0.04112189,  0.03967496,\n",
       "        0.03826557,  0.03693718,  0.03562144,  0.0331636 ,  0.03198735,\n",
       "        0.0308607 ,  0.02871297,  0.02871297,  0.02769006,  0.02575712,\n",
       "        0.02484428,  0.02483682,  0.02396299,  0.02395579,  0.02395579,\n",
       "        0.02310527,  0.02310527,  0.02310527,  0.02309832,  0.02309832,\n",
       "        0.02309832,  0.02227755,  0.02227755,  0.02071439,  0.01925294,\n",
       "        0.01925294,  0.01789812,  0.01490073,  0.01437133,  0.01437133,\n",
       "        0.01287231,  0.01287231,  0.01071068,  0.00995088,  0.00858778,\n",
       "        0.00741   ,  0.00740774,  0.00688061,  0.00593556,  0.0053117 ])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_preds[decreasing_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 50 total 1's out of 150 training examples.\n"
     ]
    }
   ],
   "source": [
    "# Now we create a loop that mimics the process of cutting a target based on the top 1%, 2%, 3%, ..., 100% of scores.\n",
    "# For each cutoff, we calculate the fraction of actual positives we've identified.\n",
    "\n",
    "# As a benchmark, the random guessing model will only accumlate actual positives in proportion to the actual\n",
    "# fraction of overall observtions that were positives.  For instance, if 20% of the population is actually a 1,\n",
    "# then when you randomly select 10% of the population, you'd expect 20% of that group to be a 1.\n",
    "\n",
    "total_ones = y_bin.sum() # Number of actual positives\n",
    "num_examples = len(y_bin) # Number of observations\n",
    "percent_ones = float(total_ones)/float(num_examples) # Fraction of positives in population\n",
    "print \"We have %s total 1's out of %s training examples.\" % (total_ones, num_examples)\n",
    "\n",
    "percent_targeted = np.linspace(0, 1, 100) # Create a sequence cutoffs (top 1%, top 2%, etc.)\n",
    "\n",
    "rands, hits = [], []\n",
    "for p in percent_targeted: # Loop over each cutoff point\n",
    "    \n",
    "    # for random targeting, we just get a constant fraction\n",
    "    rands.append(p)\n",
    "    \n",
    "    # for a real model, we take the p percent highest scorers\n",
    "    # and see how many ones there are\n",
    "    n_ones = y_bin[decreasing_order[:int(p*num_examples)]].sum()\n",
    "    hits.append(float(n_ones)/float(total_ones)) # Fraction of actual positives that we've identified thus far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAFkCAYAAAA9h3LKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117a01f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(percent_targeted, hits)\n",
    "plt.plot(percent_targeted, rands, linestyle='--')\n",
    "plt.xlabel('Percent Targeted')\n",
    "plt.ylabel('Percent of Available Positives Identified')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, if we had used our model to create a target list of customers for acquisition, then we would have identified roughly 40% of conversions by only targeting 20% of the overall population.  In general, the more a lift curve is pulled to the upper left, the better the model.  However, the shape of an optimal lift curve changes depending on the actual fraction of positives in the population, so comparing lift curves across data sets is more difficult than comparing ROC curves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using A Formula to Fit to a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[http://statsmodels.sourceforge.net/devel/examples/notebooks/generated/glm_formula.html](http://statsmodels.sourceforge.net/devel/examples/notebooks/generated/glm_formula.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Star98 dataset is an educational dataset from California counties.  The column `NABOVE` represents \"the number of 9th graders scoring over the national median value on the mathematics exam.\"  We will create a logistic regression to predict whether or not the percent of 9th graders scoring above the national medial value on the math exam exceeds 50%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[http://statsmodels.sourceforge.net/0.6.0/datasets/generated/star98.html](http://statsmodels.sourceforge.net/0.6.0/datasets/generated/star98.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "star98 = sm.datasets.star98.load_pandas().data # Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NABOVE</th>\n",
       "      <th>NBELOW</th>\n",
       "      <th>LOWINC</th>\n",
       "      <th>PERASIAN</th>\n",
       "      <th>PERBLACK</th>\n",
       "      <th>PERHISP</th>\n",
       "      <th>PERMINTE</th>\n",
       "      <th>AVYRSEXP</th>\n",
       "      <th>AVSALK</th>\n",
       "      <th>PERSPENK</th>\n",
       "      <th>...</th>\n",
       "      <th>PCTCHRT</th>\n",
       "      <th>PCTYRRND</th>\n",
       "      <th>PERMINTE_AVYRSEXP</th>\n",
       "      <th>PERMINTE_AVSAL</th>\n",
       "      <th>AVYRSEXP_AVSAL</th>\n",
       "      <th>PERSPEN_PTRATIO</th>\n",
       "      <th>PERSPEN_PCTAF</th>\n",
       "      <th>PTRATIO_PCTAF</th>\n",
       "      <th>PERMINTE_AVYRSEXP_AVSAL</th>\n",
       "      <th>PERSPEN_PTRATIO_PCTAF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>452.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>34.39730</td>\n",
       "      <td>23.299300</td>\n",
       "      <td>14.235280</td>\n",
       "      <td>11.411120</td>\n",
       "      <td>15.91837</td>\n",
       "      <td>14.70646</td>\n",
       "      <td>59.15732</td>\n",
       "      <td>4.445207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.222220</td>\n",
       "      <td>234.102872</td>\n",
       "      <td>941.68811</td>\n",
       "      <td>869.9948</td>\n",
       "      <td>96.50656</td>\n",
       "      <td>253.52242</td>\n",
       "      <td>1238.1955</td>\n",
       "      <td>13848.8985</td>\n",
       "      <td>5504.0352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>17.36507</td>\n",
       "      <td>29.328380</td>\n",
       "      <td>8.234897</td>\n",
       "      <td>9.314884</td>\n",
       "      <td>13.63636</td>\n",
       "      <td>16.08324</td>\n",
       "      <td>59.50397</td>\n",
       "      <td>5.267598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>219.316851</td>\n",
       "      <td>811.41756</td>\n",
       "      <td>957.0166</td>\n",
       "      <td>107.68435</td>\n",
       "      <td>340.40609</td>\n",
       "      <td>1321.0664</td>\n",
       "      <td>13050.2233</td>\n",
       "      <td>6958.8468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>337.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>32.64324</td>\n",
       "      <td>9.226386</td>\n",
       "      <td>42.406310</td>\n",
       "      <td>13.543720</td>\n",
       "      <td>28.83436</td>\n",
       "      <td>14.59559</td>\n",
       "      <td>60.56992</td>\n",
       "      <td>5.482922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>420.854496</td>\n",
       "      <td>1746.49488</td>\n",
       "      <td>884.0537</td>\n",
       "      <td>103.92435</td>\n",
       "      <td>295.75929</td>\n",
       "      <td>1022.4252</td>\n",
       "      <td>25491.1232</td>\n",
       "      <td>5605.8777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>395.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>11.90953</td>\n",
       "      <td>13.883090</td>\n",
       "      <td>3.796973</td>\n",
       "      <td>11.443110</td>\n",
       "      <td>11.11111</td>\n",
       "      <td>14.38939</td>\n",
       "      <td>58.33411</td>\n",
       "      <td>4.165093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>159.882095</td>\n",
       "      <td>648.15671</td>\n",
       "      <td>839.3923</td>\n",
       "      <td>90.11341</td>\n",
       "      <td>204.34375</td>\n",
       "      <td>1061.4545</td>\n",
       "      <td>9326.5797</td>\n",
       "      <td>4421.0568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>36.88889</td>\n",
       "      <td>12.187500</td>\n",
       "      <td>76.875000</td>\n",
       "      <td>7.604167</td>\n",
       "      <td>43.58974</td>\n",
       "      <td>13.90568</td>\n",
       "      <td>63.15364</td>\n",
       "      <td>4.324902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>606.144976</td>\n",
       "      <td>2752.85075</td>\n",
       "      <td>878.1943</td>\n",
       "      <td>81.22097</td>\n",
       "      <td>226.54248</td>\n",
       "      <td>983.7059</td>\n",
       "      <td>38280.2616</td>\n",
       "      <td>4254.4314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NABOVE  NBELOW    LOWINC   PERASIAN   PERBLACK    PERHISP  PERMINTE  \\\n",
       "0   452.0   355.0  34.39730  23.299300  14.235280  11.411120  15.91837   \n",
       "1   144.0    40.0  17.36507  29.328380   8.234897   9.314884  13.63636   \n",
       "2   337.0   234.0  32.64324   9.226386  42.406310  13.543720  28.83436   \n",
       "3   395.0   178.0  11.90953  13.883090   3.796973  11.443110  11.11111   \n",
       "4     8.0    57.0  36.88889  12.187500  76.875000   7.604167  43.58974   \n",
       "\n",
       "   AVYRSEXP    AVSALK  PERSPENK          ...            PCTCHRT   PCTYRRND  \\\n",
       "0  14.70646  59.15732  4.445207          ...                0.0  22.222220   \n",
       "1  16.08324  59.50397  5.267598          ...                0.0   0.000000   \n",
       "2  14.59559  60.56992  5.482922          ...                0.0   0.000000   \n",
       "3  14.38939  58.33411  4.165093          ...                0.0   7.142857   \n",
       "4  13.90568  63.15364  4.324902          ...                0.0   0.000000   \n",
       "\n",
       "   PERMINTE_AVYRSEXP  PERMINTE_AVSAL  AVYRSEXP_AVSAL  PERSPEN_PTRATIO  \\\n",
       "0         234.102872       941.68811        869.9948         96.50656   \n",
       "1         219.316851       811.41756        957.0166        107.68435   \n",
       "2         420.854496      1746.49488        884.0537        103.92435   \n",
       "3         159.882095       648.15671        839.3923         90.11341   \n",
       "4         606.144976      2752.85075        878.1943         81.22097   \n",
       "\n",
       "   PERSPEN_PCTAF  PTRATIO_PCTAF  PERMINTE_AVYRSEXP_AVSAL  \\\n",
       "0      253.52242      1238.1955               13848.8985   \n",
       "1      340.40609      1321.0664               13050.2233   \n",
       "2      295.75929      1022.4252               25491.1232   \n",
       "3      204.34375      1061.4545                9326.5797   \n",
       "4      226.54248       983.7059               38280.2616   \n",
       "\n",
       "   PERSPEN_PTRATIO_PCTAF  \n",
       "0              5504.0352  \n",
       "1              6958.8468  \n",
       "2              5605.8777  \n",
       "3              4421.0568  \n",
       "4              4254.4314  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "star98.head() # Preview the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOWINC</th>\n",
       "      <th>PERASIAN</th>\n",
       "      <th>PERBLACK</th>\n",
       "      <th>PERHISP</th>\n",
       "      <th>PCTCHRT</th>\n",
       "      <th>PCTYRRND</th>\n",
       "      <th>PERMINTE</th>\n",
       "      <th>AVYRSEXP</th>\n",
       "      <th>AVSALK</th>\n",
       "      <th>PERSPENK</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>PCTAF</th>\n",
       "      <th>SUCCESS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.39730</td>\n",
       "      <td>23.299300</td>\n",
       "      <td>14.235280</td>\n",
       "      <td>11.411120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.222220</td>\n",
       "      <td>15.91837</td>\n",
       "      <td>14.70646</td>\n",
       "      <td>59.15732</td>\n",
       "      <td>4.445207</td>\n",
       "      <td>21.71025</td>\n",
       "      <td>57.03276</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.36507</td>\n",
       "      <td>29.328380</td>\n",
       "      <td>8.234897</td>\n",
       "      <td>9.314884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.63636</td>\n",
       "      <td>16.08324</td>\n",
       "      <td>59.50397</td>\n",
       "      <td>5.267598</td>\n",
       "      <td>20.44278</td>\n",
       "      <td>64.62264</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.64324</td>\n",
       "      <td>9.226386</td>\n",
       "      <td>42.406310</td>\n",
       "      <td>13.543720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.83436</td>\n",
       "      <td>14.59559</td>\n",
       "      <td>60.56992</td>\n",
       "      <td>5.482922</td>\n",
       "      <td>18.95419</td>\n",
       "      <td>53.94191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.90953</td>\n",
       "      <td>13.883090</td>\n",
       "      <td>3.796973</td>\n",
       "      <td>11.443110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>11.11111</td>\n",
       "      <td>14.38939</td>\n",
       "      <td>58.33411</td>\n",
       "      <td>4.165093</td>\n",
       "      <td>21.63539</td>\n",
       "      <td>49.06103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.88889</td>\n",
       "      <td>12.187500</td>\n",
       "      <td>76.875000</td>\n",
       "      <td>7.604167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.58974</td>\n",
       "      <td>13.90568</td>\n",
       "      <td>63.15364</td>\n",
       "      <td>4.324902</td>\n",
       "      <td>18.77984</td>\n",
       "      <td>52.38095</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     LOWINC   PERASIAN   PERBLACK    PERHISP  PCTCHRT   PCTYRRND  PERMINTE  \\\n",
       "0  34.39730  23.299300  14.235280  11.411120      0.0  22.222220  15.91837   \n",
       "1  17.36507  29.328380   8.234897   9.314884      0.0   0.000000  13.63636   \n",
       "2  32.64324   9.226386  42.406310  13.543720      0.0   0.000000  28.83436   \n",
       "3  11.90953  13.883090   3.796973  11.443110      0.0   7.142857  11.11111   \n",
       "4  36.88889  12.187500  76.875000   7.604167      0.0   0.000000  43.58974   \n",
       "\n",
       "   AVYRSEXP    AVSALK  PERSPENK   PTRATIO     PCTAF  SUCCESS  \n",
       "0  14.70646  59.15732  4.445207  21.71025  57.03276        1  \n",
       "1  16.08324  59.50397  5.267598  20.44278  64.62264        1  \n",
       "2  14.59559  60.56992  5.482922  18.95419  53.94191        1  \n",
       "3  14.38939  58.33411  4.165093  21.63539  49.06103        1  \n",
       "4  13.90568  63.15364  4.324902  18.77984  52.38095        0  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Let's filter to a subset of columns, calculate the percentage of students above\n",
    "## the national median, and create a new binary variance that indicates if \n",
    "## the percent of students above the national median excdeeds 50%\n",
    "\n",
    "dta = star98[['NABOVE', 'NBELOW', 'LOWINC', 'PERASIAN', 'PERBLACK', 'PERHISP',\n",
    "              'PCTCHRT', 'PCTYRRND', 'PERMINTE', 'AVYRSEXP', 'AVSALK',\n",
    "              'PERSPENK', 'PTRATIO', 'PCTAF']]\n",
    "percent_above = dta['NABOVE'] / (dta['NABOVE'] + dta['NBELOW'])\n",
    "dta = dta.drop(['NABOVE', 'NBELOW'], axis=1)\n",
    "dta[\"SUCCESS\"] = percent_above>0.5\n",
    "dta[\"SUCCESS\"] = dta[\"SUCCESS\"].astype(\"int\")\n",
    "dta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create the formula representing the logistic regression, as we would in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "formula = 'SUCCESS ~ LOWINC + PERASIAN + PERBLACK + PERHISP + PCTCHRT + \\\n",
    "           PCTYRRND + PERMINTE*AVYRSEXP*AVSALK + PERSPENK*PTRATIO*PCTAF'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we fit the logistic regression by using statsmodels' ```glm``` call, and indicating that we're doing logistic regression by setting the ```family``` argument to binomial (again, as we do in R)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>SUCCESS</td>     <th>  No. Observations:  </th>  <td>   303</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>GLM</td>       <th>  Df Residuals:      </th>  <td>   282</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>       <td>Binomial</td>     <th>  Df Model:          </th>  <td>    20</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>        <td>logit</td>      <th>  Scale:             </th>    <td>1.0</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -75.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>           <td>Wed, 12 Oct 2016</td> <th>  Deviance:          </th> <td>  150.32</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>               <td>08:28:54</td>     <th>  Pearson chi2:      </th>  <td>  167.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>        <td>10</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                <td>  103.2251</td> <td>   60.567</td> <td>    1.704</td> <td> 0.088</td> <td>  -15.484   221.934</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LOWINC</th>                   <td>   -0.1344</td> <td>    0.025</td> <td>   -5.428</td> <td> 0.000</td> <td>   -0.183    -0.086</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PERASIAN</th>                 <td>    0.1567</td> <td>    0.043</td> <td>    3.662</td> <td> 0.000</td> <td>    0.073     0.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PERBLACK</th>                 <td>   -0.1568</td> <td>    0.051</td> <td>   -3.069</td> <td> 0.002</td> <td>   -0.257    -0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PERHISP</th>                  <td>   -0.0460</td> <td>    0.021</td> <td>   -2.138</td> <td> 0.033</td> <td>   -0.088    -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PCTCHRT</th>                  <td>   -0.0255</td> <td>    0.035</td> <td>   -0.723</td> <td> 0.470</td> <td>   -0.094     0.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PCTYRRND</th>                 <td>   -0.0119</td> <td>    0.012</td> <td>   -1.025</td> <td> 0.306</td> <td>   -0.035     0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PERMINTE</th>                 <td>   -3.9382</td> <td>    4.239</td> <td>   -0.929</td> <td> 0.353</td> <td>  -12.246     4.369</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AVYRSEXP</th>                 <td>   -2.6731</td> <td>    3.176</td> <td>   -0.842</td> <td> 0.400</td> <td>   -8.898     3.552</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PERMINTE:AVYRSEXP</th>        <td>    0.2827</td> <td>    0.294</td> <td>    0.960</td> <td> 0.337</td> <td>   -0.294     0.860</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AVSALK</th>                   <td>   -0.6330</td> <td>    0.820</td> <td>   -0.772</td> <td> 0.440</td> <td>   -2.240     0.974</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PERMINTE:AVSALK</th>          <td>    0.0720</td> <td>    0.073</td> <td>    0.981</td> <td> 0.326</td> <td>   -0.072     0.216</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AVYRSEXP:AVSALK</th>          <td>    0.0492</td> <td>    0.056</td> <td>    0.876</td> <td> 0.381</td> <td>   -0.061     0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PERMINTE:AVYRSEXP:AVSALK</th> <td>   -0.0052</td> <td>    0.005</td> <td>   -1.021</td> <td> 0.307</td> <td>   -0.015     0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PERSPENK</th>                 <td>  -18.6489</td> <td>   11.248</td> <td>   -1.658</td> <td> 0.097</td> <td>  -40.694     3.396</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PTRATIO</th>                  <td>   -2.8709</td> <td>    2.303</td> <td>   -1.247</td> <td> 0.213</td> <td>   -7.385     1.643</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PERSPENK:PTRATIO</th>         <td>    0.8320</td> <td>    0.539</td> <td>    1.544</td> <td> 0.123</td> <td>   -0.224     1.888</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PCTAF</th>                    <td>   -1.8809</td> <td>    1.305</td> <td>   -1.441</td> <td> 0.150</td> <td>   -4.440     0.678</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PERSPENK:PCTAF</th>           <td>    0.5528</td> <td>    0.304</td> <td>    1.816</td> <td> 0.069</td> <td>   -0.044     1.149</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PTRATIO:PCTAF</th>            <td>    0.0838</td> <td>    0.061</td> <td>    1.369</td> <td> 0.171</td> <td>   -0.036     0.204</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PERSPENK:PTRATIO:PCTAF</th>   <td>   -0.0244</td> <td>    0.015</td> <td>   -1.678</td> <td> 0.093</td> <td>   -0.053     0.004</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                SUCCESS   No. Observations:                  303\n",
       "Model:                            GLM   Df Residuals:                      282\n",
       "Model Family:                Binomial   Df Model:                           20\n",
       "Link Function:                  logit   Scale:                             1.0\n",
       "Method:                          IRLS   Log-Likelihood:                -75.162\n",
       "Date:                Wed, 12 Oct 2016   Deviance:                       150.32\n",
       "Time:                        08:28:54   Pearson chi2:                     167.\n",
       "No. Iterations:                    10                                         \n",
       "============================================================================================\n",
       "                               coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "--------------------------------------------------------------------------------------------\n",
       "Intercept                  103.2251     60.567      1.704      0.088       -15.484   221.934\n",
       "LOWINC                      -0.1344      0.025     -5.428      0.000        -0.183    -0.086\n",
       "PERASIAN                     0.1567      0.043      3.662      0.000         0.073     0.241\n",
       "PERBLACK                    -0.1568      0.051     -3.069      0.002        -0.257    -0.057\n",
       "PERHISP                     -0.0460      0.021     -2.138      0.033        -0.088    -0.004\n",
       "PCTCHRT                     -0.0255      0.035     -0.723      0.470        -0.094     0.044\n",
       "PCTYRRND                    -0.0119      0.012     -1.025      0.306        -0.035     0.011\n",
       "PERMINTE                    -3.9382      4.239     -0.929      0.353       -12.246     4.369\n",
       "AVYRSEXP                    -2.6731      3.176     -0.842      0.400        -8.898     3.552\n",
       "PERMINTE:AVYRSEXP            0.2827      0.294      0.960      0.337        -0.294     0.860\n",
       "AVSALK                      -0.6330      0.820     -0.772      0.440        -2.240     0.974\n",
       "PERMINTE:AVSALK              0.0720      0.073      0.981      0.326        -0.072     0.216\n",
       "AVYRSEXP:AVSALK              0.0492      0.056      0.876      0.381        -0.061     0.159\n",
       "PERMINTE:AVYRSEXP:AVSALK    -0.0052      0.005     -1.021      0.307        -0.015     0.005\n",
       "PERSPENK                   -18.6489     11.248     -1.658      0.097       -40.694     3.396\n",
       "PTRATIO                     -2.8709      2.303     -1.247      0.213        -7.385     1.643\n",
       "PERSPENK:PTRATIO             0.8320      0.539      1.544      0.123        -0.224     1.888\n",
       "PCTAF                       -1.8809      1.305     -1.441      0.150        -4.440     0.678\n",
       "PERSPENK:PCTAF               0.5528      0.304      1.816      0.069        -0.044     1.149\n",
       "PTRATIO:PCTAF                0.0838      0.061      1.369      0.171        -0.036     0.204\n",
       "PERSPENK:PTRATIO:PCTAF      -0.0244      0.015     -1.678      0.093        -0.053     0.004\n",
       "============================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod1 = smf.glm(formula=formula, data=dta, family=sm.families.Binomial()).fit()\n",
    "mod1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept                   103.225061\n",
      "LOWINC                       -0.134375\n",
      "PERASIAN                      0.156722\n",
      "PERBLACK                     -0.156807\n",
      "PERHISP                      -0.045952\n",
      "PCTCHRT                      -0.025470\n",
      "PCTYRRND                     -0.011937\n",
      "PERMINTE                     -3.938244\n",
      "AVYRSEXP                     -2.673062\n",
      "PERMINTE:AVYRSEXP             0.282675\n",
      "AVSALK                       -0.632951\n",
      "PERMINTE:AVSALK               0.072025\n",
      "AVYRSEXP:AVSALK               0.049215\n",
      "PERMINTE:AVYRSEXP:AVSALK     -0.005188\n",
      "PERSPENK                    -18.648906\n",
      "PTRATIO                      -2.870892\n",
      "PERSPENK:PTRATIO              0.832023\n",
      "PCTAF                        -1.880869\n",
      "PERSPENK:PCTAF                0.552780\n",
      "PTRATIO:PCTAF                 0.083849\n",
      "PERSPENK:PTRATIO:PCTAF       -0.024427\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(mod1.params)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
